{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Model Request Fields with Amazon Bedrock in AG2\n",
    "\n",
    "This notebook demonstrates how to use **`additional_model_request_fields`** with Amazon Bedrock in AG2. This feature allows you to pass model-specific parameters directly to the Bedrock API, including advanced features like Claude's **thinking configuration**.\n",
    "\n",
    "## What are Additional Model Request Fields?\n",
    "\n",
    "`additional_model_request_fields` is a powerful feature that enables you to:\n",
    "- **Pass model-specific parameters**: Access Bedrock features not directly exposed in AG2's standard configuration\n",
    "- **Enable advanced features**: Use cutting-edge capabilities like Claude's thinking mode\n",
    "- **Customize model behavior**: Fine-tune model responses with provider-specific options\n",
    "- **Future-proof your code**: Easily adopt new Bedrock features as they become available\n",
    "\n",
    "## How It Works\n",
    "\n",
    "When you provide `additional_model_request_fields` in your LLM configuration, AG2:\n",
    "1. Extracts these fields from your config\n",
    "2. Passes them directly to Bedrock's `additional_model_request_fields` parameter\n",
    "3. Allows the model to use these advanced features\n",
    "\n",
    "This is particularly useful for features like:\n",
    "- **Thinking mode** (Claude models): Extended reasoning with configurable token budgets\n",
    "- **Model-specific parameters**: Any parameter supported by your chosen Bedrock model\n",
    "- **Experimental features**: New capabilities before they're fully integrated into AG2\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Python >= 3.10\n",
    "- AG2 installed with bedrock extra: `pip install ag2[bedrock]`\n",
    "- AWS credentials configured (via environment variables, IAM role, or AWS credentials file)\n",
    "- A Bedrock model that supports the features you want to use\n",
    "\n",
    "## Model Compatibility\n",
    "\n",
    "**Thinking Configuration** is supported by:\n",
    "- `anthropic.claude-3-7-sonnet-20250219-v1:0` (and newer Claude models)\n",
    "- `eu.anthropic.claude-3-7-sonnet-20250219-v1:0` (EU region)\n",
    "\n",
    "Check the [Bedrock model documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html) for the latest list of models and their supported features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install required packages if not already installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ag2[bedrock] python-dotenv --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries and Configure AWS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Thinking Configuration\n",
    "\n",
    "Claude's **thinking configuration** enables extended reasoning capabilities. When enabled, the model can:\n",
    "- Perform deeper reasoning before generating a response\n",
    "- Use a configurable token budget for internal \"thinking\"\n",
    "- Show more thorough problem-solving processes\n",
    "\n",
    "### Thinking Configuration Parameters\n",
    "\n",
    "- **`type`**: Set to `\"enabled\"` to activate thinking mode\n",
    "- **`budget_tokens`**: Maximum number of tokens the model can use for thinking (must be less than `max_tokens`)\n",
    "\n",
    "**Important**: When using thinking mode, ensure your `max_tokens` is greater than `budget_tokens` to allow space for both thinking and the actual response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Basic Example - Enabling Thinking Mode\n",
    "\n",
    "Let's create a basic example using thinking configuration, similar to the test.py reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LLM with Bedrock and thinking mode enabled\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"bedrock\",\n",
    "        \"model\": \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        \"api_key\": os.getenv(\"BEDROCK_API_KEY\"),\n",
    "        \"aws_region\": os.getenv(\"AWS_REGION\"),\n",
    "        \"aws_access_key\": os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "        \"aws_secret_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"aws_profile_name\": os.getenv(\"AWS_PROFILE\"),\n",
    "        # Enable thinking mode via additional_model_request_fields\n",
    "        \"additional_model_request_fields\": {\n",
    "            \"thinking\": {\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": 1024,  # Allocate 1024 tokens for thinking\n",
    "            }\n",
    "        },\n",
    "        \"temperature\": 1,\n",
    "        \"max_tokens\": 4096,  # Must be greater than budget_tokens\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Bedrock LLM configuration created with thinking mode enabled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with thinking mode\n",
    "conv_agent = ConversableAgent(\n",
    "    name=\"conv_agent\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"You are a helpful assistant that thinks deeply about problems before responding.\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "print(f\"Agent '{conv_agent.name}' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Example 1 - Simple Question with Thinking\n",
    "\n",
    "Let's test the agent with a question that benefits from extended reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 1: Simple question with thinking mode ===\")\n",
    "\n",
    "result = conv_agent.run(\n",
    "    message=\"What is the capital of France? Also add a small research on it.\",\n",
    "    max_turns=5,\n",
    ").process()\n",
    "\n",
    "print(\"\\nResponse received!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Example 2 - Complex Reasoning Problem\n",
    "\n",
    "Thinking mode is particularly useful for complex problems that require deep reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 2: Complex reasoning problem ===\")\n",
    "\n",
    "complex_result = conv_agent.run(\n",
    "    message=\"\"\"Analyze the following scenario: A company wants to reduce its carbon footprint by 50% over 5 years.\n",
    "    They currently use 100% fossil fuel energy. They're considering:\n",
    "    1. Switching to renewable energy (solar/wind)\n",
    "    2. Implementing energy efficiency measures\n",
    "    3. Carbon offset programs\n",
    "\n",
    "    What combination of strategies would be most effective? Consider cost, feasibility, and long-term impact.\"\"\",\n",
    "    max_turns=5,\n",
    ").process()\n",
    "\n",
    "print(\"\\nComplex reasoning response received!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adjusting Thinking Budget\n",
    "\n",
    "You can adjust the `budget_tokens` based on your needs:\n",
    "- **incorrect budget (<1024 tokens)**: tokens below 1024 should throw ValidationException\n",
    "- **Medium budget (1024-2048 tokens)**: Balanced reasoning for most problems\n",
    "- **Higher budget (2048-4096 tokens)**: For very complex problems requiring deep analysis\n",
    "\n",
    "**Note**: Higher budgets increase token usage and cost, but may improve response quality for complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with different thinking budgets\n",
    "thinking_configs = {\n",
    "    \"incorrect\": {\"type\": \"enabled\", \"budget_tokens\": 512},\n",
    "    \"medium\": {\"type\": \"enabled\", \"budget_tokens\": 1024},\n",
    "    \"high\": {\"type\": \"enabled\", \"budget_tokens\": 2048},\n",
    "}\n",
    "\n",
    "# Create config with medium thinking budget\n",
    "llm_config_incorrect = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"bedrock\",\n",
    "        \"model\": \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        \"api_key\": os.getenv(\"BEDROCK_API_KEY\"),\n",
    "        \"aws_region\": os.getenv(\"AWS_REGION\"),\n",
    "        \"aws_access_key\": os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "        \"aws_secret_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"aws_profile_name\": os.getenv(\"AWS_PROFILE\"),\n",
    "        \"additional_model_request_fields\": {\"thinking\": thinking_configs[\"incorrect\"]},\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"Configuration with medium thinking budget created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_agent = ConversableAgent(\n",
    "    name=\"conv_agent\",\n",
    "    llm_config=llm_config_incorrect,\n",
    "    system_message=\"You are a helpful assistant that thinks deeply about problems before responding.\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "conv_agent.run(\n",
    "    message=\"what is the capital of France? also research on nearby area.\",\n",
    "    max_turns=5,\n",
    ").process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've learned:\n",
    "\n",
    "1. ✅ What `additional_model_request_fields` is and how it works\n",
    "2. ✅ How to enable Claude's thinking configuration\n",
    "3. ✅ How to configure thinking budget tokens\n",
    "4. ✅ How the feature works under the hood\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **`additional_model_request_fields`** allows you to pass model-specific parameters to Bedrock\n",
    "- **Thinking mode** enables extended reasoning with configurable token budgets\n",
    "- Always ensure `max_tokens > budget_tokens` when using thinking mode\n",
    "- Thinking mode is particularly useful for complex reasoning tasks\n",
    "- Monitor token usage and costs when using extended thinking\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Experiment with different `budget_tokens` values for your use cases\n",
    "- Try combining thinking mode with other AG2 features\n",
    "- Explore other `additional_model_request_fields` supported by your Bedrock model\n",
    "- Check AWS Bedrock documentation for new features and capabilities\n",
    "\n",
    "## References\n",
    "\n",
    "- [AG2 Documentation](https://docs.ag2.ai)\n",
    "- [Bedrock Converse API](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html)\n",
    "- [AWS Bedrock Model IDs](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html)\n",
    "- [Claude Thinking Mode Documentation](https://docs.anthropic.com/claude/docs/thinking)"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Additional Model Request Fields with Amazon Bedrock in AG2",
   "tags": [
    "models",
    "bedrock",
    "amazon"
   ]
  },
  "kernelspec": {
   "display_name": "ag2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
