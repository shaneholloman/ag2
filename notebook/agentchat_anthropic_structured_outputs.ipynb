{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic Structured Outputs with AG2\n",
    "\n",
    "**Author:** Yixuan Zhai\n",
    "\n",
    "This notebook demonstrates how to use Anthropic's structured outputs feature with AG2 agents. Structured outputs guarantee schema-compliant responses through constrained decoding, eliminating parsing errors and ensuring type safety.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Anthropic's structured outputs feature provides two powerful modes:\n",
    "\n",
    "1. **JSON Outputs** (`response_format`): Get validated JSON responses matching a specific schema\n",
    "2. **Strict Tool Use** (`strict: true`): Guaranteed schema validation for tool inputs\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "- **Always Valid**: No more `JSON.parse()` errors\n",
    "- **Type Safe**: Guaranteed field types and required fields\n",
    "- **Reliable**: No retries needed for schema violations\n",
    "- **Dual Modes**: JSON for data extraction, strict tools for agentic workflows\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Claude Sonnet 4.5 (`claude-sonnet-4-5`) or Claude Opus 4.1 (`claude-opus-4-1`)\n",
    "- Anthropic SDK >= 0.74.1\n",
    "- Beta header: `structured-outputs-2025-11-13` (automatically applied by AG2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required dependencies and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import autogen\n",
    "\n",
    "# Ensure you have your Anthropic API key set\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "# Verify the API key is set\n",
    "assert os.getenv(\"ANTHROPIC_API_KEY\"), \"Please set ANTHROPIC_API_KEY environment variable\"\n",
    "print(\"✅ Environment configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: JSON Structured Outputs with Pydantic Models\n",
    "\n",
    "The most common use case is extracting structured data from unstructured text. We'll use Pydantic models to define our schema and get validated JSON responses.\n",
    "\n",
    "### Use Case: Mathematical Reasoning\n",
    "\n",
    "Let's create an agent that solves math problems and returns structured step-by-step reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structured output schema using Pydantic\n",
    "class Step(BaseModel):\n",
    "    \"\"\"A single step in mathematical reasoning.\"\"\"\n",
    "\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    \"\"\"Structured output for mathematical problem solving.\"\"\"\n",
    "\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "    def format(self) -> str:\n",
    "        \"\"\"Format the response for display.\"\"\"\n",
    "        steps_output = \"\\n\".join(\n",
    "            f\"Step {i + 1}: {step.explanation}\\n  Output: {step.output}\" for i, step in enumerate(self.steps)\n",
    "        )\n",
    "        return f\"{steps_output}\\n\\nFinal Answer: {self.final_answer}\"\n",
    "\n",
    "\n",
    "# Configure LLM with structured output\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "            \"api_type\": \"anthropic\",\n",
    "            \"response_format\": MathReasoning,  # Enable structured outputs\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create agents\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=0,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "math_assistant = autogen.AssistantAgent(\n",
    "    name=\"MathAssistant\",\n",
    "    system_message=\"You are a math tutor. Solve problems step by step.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "print(\"✅ Example 1 configured: Math reasoning with structured outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the assistant to solve a math problem\n",
    "chat_result = user_proxy.initiate_chat(\n",
    "    math_assistant,\n",
    "    message=\"Solve the equation: 3x + 7 = 22\",\n",
    "    max_turns=1,\n",
    ")\n",
    "\n",
    "# The response is automatically formatted using the format() method\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STRUCTURED OUTPUT RESULT:\")\n",
    "print(\"=\" * 60)\n",
    "print(chat_result.chat_history[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How It Works\n",
    "\n",
    "1. **Schema Definition**: Pydantic models define the expected structure\n",
    "2. **Beta API**: AG2 automatically uses `beta.messages.parse()` for Pydantic models\n",
    "3. **Constrained Decoding**: Claude generates output that strictly follows the schema\n",
    "4. **FormatterProtocol**: If your model has a `format()` method, it's automatically called\n",
    "\n",
    "**Benefits**:\n",
    "- ✅ No JSON parsing errors\n",
    "- ✅ Guaranteed schema compliance\n",
    "- ✅ Type-safe field access\n",
    "- ✅ Custom formatting support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Strict Tool Use for Type-Safe Function Calls\n",
    "\n",
    "Strict tool use ensures that Claude's tool inputs exactly match your schema. This is critical for production agentic systems where invalid parameters can break workflows.\n",
    "\n",
    "### Use Case: Weather API with Validated Inputs\n",
    "\n",
    "Without strict mode, Claude might return `\"celsius\"` as a string when you expect an enum, or `\"2\"` instead of `2`. Strict mode guarantees correct types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool function\n",
    "def get_weather(location: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"Get the weather for a location.\n",
    "\n",
    "    Args:\n",
    "        location: The city and state, e.g. San Francisco, CA\n",
    "        unit: Temperature unit (celsius or fahrenheit)\n",
    "    \"\"\"\n",
    "    # In a real application, this would call a weather API\n",
    "    return f\"Weather in {location}: 22°{unit.upper()[0]}, partly cloudy\"\n",
    "\n",
    "\n",
    "# Configure LLM with strict tool\n",
    "llm_config_strict = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "            \"api_type\": \"anthropic\",\n",
    "        }\n",
    "    ],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the weather for a location\",\n",
    "            \"strict\": True,  # Enable strict schema validation ✨\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"},\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"Temperature unit\"},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create agents\n",
    "weather_assistant = autogen.AssistantAgent(\n",
    "    name=\"WeatherAssistant\",\n",
    "    system_message=\"You help users get weather information. Use the get_weather function.\",\n",
    "    llm_config=llm_config_strict,\n",
    ")\n",
    "\n",
    "user_proxy_2 = autogen.UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "# Register function on both agents\n",
    "# Assistant needs it for LLM awareness, UserProxy executes it\n",
    "weather_assistant.register_function({\"get_weather\": get_weather})\n",
    "user_proxy_2.register_function({\"get_weather\": get_weather})\n",
    "\n",
    "print(\"✅ Example 2 configured: Strict tool use for weather queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the weather\n",
    "chat_result = user_proxy_2.initiate_chat(\n",
    "    weather_assistant,\n",
    "    message=\"What's the weather in Boston, MA?\",\n",
    "    max_turns=2,\n",
    ")\n",
    "\n",
    "# Verify tool call had strict typing\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TOOL CALL VERIFICATION:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import json\n",
    "\n",
    "for message in chat_result.chat_history:\n",
    "    if message.get(\"tool_calls\"):\n",
    "        tool_call = message[\"tool_calls\"][0]\n",
    "        args = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "        print(f\"Function: {tool_call['function']['name']}\")\n",
    "        print(f\"Arguments: {args}\")\n",
    "        print(f\"✅ location type: {type(args['location']).__name__}\")\n",
    "        if \"unit\" in args:\n",
    "            print(f\"✅ unit value: {args['unit']} (valid enum)\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Strict Tool Use Matters\n",
    "\n",
    "**Without `strict: true`:**\n",
    "- Claude might return `{\"location\": \"Boston\", \"unit\": \"Celsius\"}` (wrong case)\n",
    "- Or `{\"passengers\": \"2\"}` instead of `{\"passengers\": 2}` (string vs int)\n",
    "- Missing required fields could cause runtime errors\n",
    "\n",
    "**With `strict: true`:**\n",
    "- ✅ Types are guaranteed correct (`int` not `\"2\"`)\n",
    "- ✅ Enums match exactly (`\"celsius\"` not `\"Celsius\"`)\n",
    "- ✅ Required fields are always present\n",
    "- ✅ No need for validation code in your functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Combined JSON Outputs + Strict Tools\n",
    "\n",
    "The most powerful pattern is combining both features: use strict tools for calculations/actions, then return structured JSON for the final result.\n",
    "\n",
    "### Use Case: Math Calculator Agent\n",
    "\n",
    "The agent uses strict tools to perform calculations (guaranteed correct types), then provides a structured summary of the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define calculator tool\n",
    "def calculate(operation: str, a: float, b: float) -> float:\n",
    "    \"\"\"Perform a calculation.\n",
    "\n",
    "    Args:\n",
    "        operation: The operation to perform (add, subtract, multiply, divide)\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \"\"\"\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    elif operation == \"subtract\":\n",
    "        return a - b\n",
    "    elif operation == \"multiply\":\n",
    "        return a * b\n",
    "    elif operation == \"divide\":\n",
    "        return a / b if b != 0 else 0\n",
    "    return 0\n",
    "\n",
    "\n",
    "# Result model for structured output\n",
    "class CalculationResult(BaseModel):\n",
    "    \"\"\"Structured output for calculation results.\"\"\"\n",
    "\n",
    "    problem: str\n",
    "    steps: list[str]\n",
    "    result: float\n",
    "    verification: str\n",
    "\n",
    "\n",
    "# Configure with BOTH features\n",
    "llm_config_combined = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "            \"api_type\": \"anthropic\",\n",
    "            \"response_format\": CalculationResult,  # 1. Structured JSON output\n",
    "        }\n",
    "    ],\n",
    "    \"functions\": [\n",
    "        {  # 2. Strict tool validation\n",
    "            \"name\": \"calculate\",\n",
    "            \"description\": \"Perform arithmetic calculation\",\n",
    "            \"strict\": True,  # Enable strict mode\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"operation\": {\"type\": \"string\", \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"]},\n",
    "                    \"a\": {\"type\": \"number\"},\n",
    "                    \"b\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"operation\", \"a\", \"b\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create agents\n",
    "calc_assistant = autogen.AssistantAgent(\n",
    "    name=\"MathAssistant\",\n",
    "    system_message=\"You solve math problems using tools and provide structured results.\",\n",
    "    llm_config=llm_config_combined,\n",
    ")\n",
    "\n",
    "user_proxy_3 = autogen.UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=5,\n",
    "    code_execution_config=False,\n",
    ")\n",
    "\n",
    "# Register function on both agents\n",
    "calc_assistant.register_function({\"calculate\": calculate})\n",
    "user_proxy_3.register_function({\"calculate\": calculate})\n",
    "\n",
    "print(\"✅ Example 3 configured: Combined strict tools + structured output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask for a calculation with explanation\n",
    "chat_result = user_proxy_3.initiate_chat(\n",
    "    calc_assistant,\n",
    "    message=\"Calculate (15 + 7) * 3 and explain your steps\",\n",
    "    max_turns=6,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMBINED FEATURES RESULT:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for tool calls (strict validation)\n",
    "found_tool_call = False\n",
    "found_structured_output = False\n",
    "\n",
    "for message in chat_result.chat_history:\n",
    "    if message.get(\"tool_calls\"):\n",
    "        found_tool_call = True\n",
    "        tool_call = message[\"tool_calls\"][0]\n",
    "        args = json.loads(tool_call[\"function\"][\"arguments\"])\n",
    "        print(f\"\\n✅ Tool Call: {tool_call['function']['name']}\")\n",
    "        print(f\"   Arguments: {args}\")\n",
    "        print(f\"   Types verified: a={type(args['a']).__name__}, b={type(args['b']).__name__}\")\n",
    "\n",
    "    # Check for structured output\n",
    "    if message.get(\"role\") == \"assistant\" and message.get(\"content\"):\n",
    "        result = CalculationResult.model_validate_json(message[\"content\"])\n",
    "        found_structured_output = True\n",
    "        print(\"\\n✅ Structured Output:\")\n",
    "        print(f\"   Problem: {result.problem}\")\n",
    "        print(f\"   Steps: {len(result.steps)} steps\")\n",
    "        print(f\"   Result: {result.result}\")\n",
    "        print(f\"   Verification: {result.verification}\")\n",
    "\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\n",
    "    f\"Features used: Tool Calls={'✅' if found_tool_call else '❌'} | Structured Output={'✅' if found_structured_output else '❌'}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Combined Mode Works\n",
    "\n",
    "When both `response_format` and `strict: true` tools are configured:\n",
    "\n",
    "1. **AG2 uses `beta.messages.create()`** (not `parse()`) to support tools\n",
    "2. **Claude chooses the approach** based on the task:\n",
    "   - Makes tool calls for calculations/actions\n",
    "   - Returns structured output for final summaries\n",
    "3. **Both features use the same beta API** with `structured-outputs-2025-11-13` header\n",
    "\n",
    "**Benefits**:\n",
    "- ✅ Type-safe tool calls (no `\"2\"` vs `2` issues)\n",
    "- ✅ Structured final output (guaranteed schema)\n",
    "- ✅ Production-ready reliability\n",
    "- ✅ No manual validation needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: GroupChat with AutoPattern and Structured Outputs\n",
    "\n",
    "Multi-agent collaboration becomes even more powerful with structured outputs. Let's build a research team where agents automatically coordinate using AutoPattern and produce a structured research report.\n",
    "\n",
    "### Use Case: Collaborative Research Analysis\n",
    "\n",
    "Three specialized agents collaborate to analyze a topic, with automatic speaker selection and a guaranteed structured output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define structured output for research report\n",
    "class ResearchFinding(BaseModel):\n",
    "    \"\"\"A single research finding.\"\"\"\n",
    "\n",
    "    category: str\n",
    "    finding: str\n",
    "    confidence: str  # high, medium, low\n",
    "\n",
    "\n",
    "class ResearchReport(BaseModel):\n",
    "    \"\"\"Structured output for collaborative research.\"\"\"\n",
    "\n",
    "    topic: str\n",
    "    summary: str\n",
    "    findings: list[ResearchFinding]\n",
    "    recommendations: list[str]\n",
    "    contributors: list[str]\n",
    "\n",
    "    def format(self) -> str:\n",
    "        \"\"\"Format the research report for display.\"\"\"\n",
    "        output = f\"# Research Report: {self.topic}\\n\\n\"\n",
    "        output += f\"## Summary\\n{self.summary}\\n\\n\"\n",
    "        output += f\"## Findings ({len(self.findings)} total)\\n\"\n",
    "        for i, finding in enumerate(self.findings):\n",
    "            output += f\"{i + 1}. [{finding.category}] {finding.finding} (Confidence: {finding.confidence})\\n\"\n",
    "        output += \"\\n## Recommendations\\n\"\n",
    "        for i, rec in enumerate(self.recommendations):\n",
    "            output += f\"{i + 1}. {rec}\\n\"\n",
    "        output += f\"\\n## Contributors: {', '.join(self.contributors)}\"\n",
    "        return output\n",
    "\n",
    "\n",
    "# Define a research tool\n",
    "def search_literature(query: str, field: str) -> str:\n",
    "    \"\"\"Search academic literature for a query in a specific field.\n",
    "\n",
    "    Args:\n",
    "        query: The search query\n",
    "        field: The field to search (computer_science, biology, physics)\n",
    "    \"\"\"\n",
    "    # Simulated literature search results\n",
    "    results = {\n",
    "        \"computer_science\": \"Recent advances in LLMs show 40% improvement in reasoning tasks.\",\n",
    "        \"biology\": \"Studies indicate protein folding accuracy increased by 35% with AI models.\",\n",
    "        \"physics\": \"Quantum computing simulations demonstrate 50x speedup on specific problems.\",\n",
    "    }\n",
    "    return results.get(field, \"No results found for this field.\")\n",
    "\n",
    "\n",
    "# Configure LLM for group agents with strict tools\n",
    "llm_config_group = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "            \"api_type\": \"anthropic\",\n",
    "        }\n",
    "    ],\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"search_literature\",\n",
    "            \"description\": \"Search academic literature in a specific field\",\n",
    "            \"strict\": True,\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"The search query\"},\n",
    "                    \"field\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"computer_science\", \"biology\", \"physics\"],\n",
    "                        \"description\": \"The academic field\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\", \"field\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Configure LLM for report writer with structured output\n",
    "llm_config_report = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "            \"api_type\": \"anthropic\",\n",
    "            \"response_format\": ResearchReport,  # Structured output for final report\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create specialized research agents\n",
    "cs_researcher = autogen.AssistantAgent(\n",
    "    name=\"CS_Researcher\",\n",
    "    system_message=\"You are a computer science researcher. Analyze AI and ML topics. Use search_literature when needed.\",\n",
    "    llm_config=llm_config_group,\n",
    ")\n",
    "\n",
    "bio_researcher = autogen.AssistantAgent(\n",
    "    name=\"Bio_Researcher\",\n",
    "    system_message=\"You are a biology researcher. Analyze biological and medical topics. Use search_literature when needed.\",\n",
    "    llm_config=llm_config_group,\n",
    ")\n",
    "\n",
    "report_writer = autogen.AssistantAgent(\n",
    "    name=\"Report_Writer\",\n",
    "    system_message=\"You synthesize research from other agents into comprehensive structured reports. Wait for all researchers to contribute before writing the final report.\",\n",
    "    llm_config=llm_config_report,\n",
    ")\n",
    "\n",
    "# Register search function on all researchers\n",
    "for agent in [cs_researcher, bio_researcher]:\n",
    "    agent.register_function({\"search_literature\": search_literature})\n",
    "\n",
    "print(\"✅ Example 4 configured: GroupChat with AutoPattern and structured outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AutoPattern for intelligent speaker selection\n",
    "from autogen.agentchat.group.multi_agent_chat import initiate_group_chat\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "\n",
    "llm_config_manager = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"claude-sonnet-4-5\",\n",
    "            \"api_key\": os.environ[\"ANTHROPIC_API_KEY\"],\n",
    "            \"api_type\": \"anthropic\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Initialize pattern with agents - AutoPattern uses agents' existing llm_config\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=cs_researcher,\n",
    "    agents=[cs_researcher, bio_researcher, report_writer],\n",
    "    group_manager_args={\"llm_config\": llm_config_manager},\n",
    ")\n",
    "\n",
    "# Create initial research task\n",
    "research_task = \"\"\"\n",
    "Analyze the impact of AI on scientific research across different fields.\n",
    "Each researcher should contribute findings from their domain, then the report writer\n",
    "should create a comprehensive structured report with all findings and recommendations.\n",
    "\"\"\"\n",
    "\n",
    "# Initiate group chat\n",
    "chat_result, context_variables, last_agent = initiate_group_chat(\n",
    "    pattern=pattern,\n",
    "    messages=research_task,\n",
    "    max_rounds=8,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GROUPCHAT WITH STRUCTURED OUTPUT:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal messages: {len(chat_result.chat_history)}\")\n",
    "print(f\"Last agent: {last_agent.name}\")\n",
    "\n",
    "# Display the structured research report\n",
    "for message in chat_result.chat_history:\n",
    "    if message.get(\"name\") == \"Report_Writer\" and message.get(\"content\"):\n",
    "        # Try to parse as ResearchReport\n",
    "        report = ResearchReport.model_validate_json(message[\"content\"])\n",
    "        print(f\"\\n{report.format()}\")\n",
    "        print(f\"\\n✅ Structured report generated with {len(report.findings)} findings\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupChat Features Demonstrated\n",
    "\n",
    "**AutoPattern Benefits**:\n",
    "- **Automatic Speaker Selection**: Claude intelligently chooses which researcher to speak based on conversation context\n",
    "- **No Manual Orchestration**: No need to specify speaker order or transitions\n",
    "- **Natural Collaboration**: Agents coordinate organically based on the conversation flow\n",
    "- **Flexible Configuration**: Simple setup with model and API key\n",
    "\n",
    "**Structured Outputs in GroupChat**:\n",
    "- ✅ Individual agents use strict tools (`search_literature`) with type validation\n",
    "- ✅ Report writer produces guaranteed structured output (`ResearchReport`)\n",
    "- ✅ Multi-agent contributions synthesized into single validated schema\n",
    "- ✅ FormatterProtocol provides clean, readable final output\n",
    "\n",
    "**Key Implementation Details**:\n",
    "- Each agent can have different `llm_config` and `response_format`\n",
    "- Tools registered per agent (only researchers get `search_literature`)\n",
    "- AutoPattern manages speaker selection using Claude's intelligent routing\n",
    "- Structured output typically comes from a dedicated \"synthesis\" agent at the end\n",
    "\n",
    "**Production Considerations**:\n",
    "- Set appropriate `max_rounds` to allow sufficient collaboration (8-15 rounds typical)\n",
    "- Use descriptive system messages to guide agent behavior\n",
    "- Consider adding termination conditions for cost control\n",
    "- Context is automatically managed across all agents in the group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Considerations\n",
    "\n",
    "### Performance\n",
    "\n",
    "- **First request latency**: Grammar compilation adds latency on first use\n",
    "- **Automatic caching**: Compiled grammars cached for 24 hours\n",
    "- **Cache invalidation**: Changing schema structure invalidates cache\n",
    "\n",
    "### JSON Schema Limitations\n",
    "\n",
    "**Supported**:\n",
    "- All basic types: object, array, string, integer, number, boolean, null\n",
    "- `enum` (strings, numbers, bools only)\n",
    "- `required` and `additionalProperties: false`\n",
    "- String formats: date-time, email, uri, uuid, etc.\n",
    "\n",
    "**Not supported**:\n",
    "- Recursive schemas\n",
    "- Numerical constraints (minimum, maximum)\n",
    "- String constraints (minLength, maxLength)\n",
    "- Complex regex patterns\n",
    "\n",
    "### Model Requirements\n",
    "\n",
    "- **Required**: Claude Sonnet 4.5 or Claude Opus 4.1\n",
    "- **Older models**: Will error if `strict: true` used\n",
    "- **Fallback**: Use JSON Mode for older models (automatic in AG2)\n",
    "\n",
    "### Feature Compatibility\n",
    "\n",
    "**Works with**: ✅ Batch processing, ✅ Streaming, ✅ Token counting, ✅ Group chats\n",
    "\n",
    "**Incompatible**: ❌ Citations, ❌ Message prefilling with JSON outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "| Feature | When to Use | Configuration |\n",
    "|---------|-------------|---------------|\n",
    "| **JSON Outputs** | Data extraction, classification, API responses | `response_format: PydanticModel` |\n",
    "| **Strict Tools** | Agentic workflows, type-safe function calls | `\"strict\": True` in tool definition |\n",
    "| **Combined** | Complex agents with tools + structured results | Both configurations |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Always valid**: Structured outputs eliminate JSON parsing errors\n",
    "2. **Type safe**: Guaranteed correct types for tool inputs and JSON fields\n",
    "3. **Production ready**: No retries or manual validation needed\n",
    "4. **Two modes**: Choose based on your use case (extraction vs tools)\n",
    "5. **Automatic**: AG2 handles beta API, headers, and schema transformation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore GroupChat with structured outputs\n",
    "- Implement custom FormatterProtocol methods\n",
    "- Build multi-tool agentic workflows with strict validation\n",
    "- Combine with streaming for real-time structured responses\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Anthropic Structured Outputs Documentation](https://docs.anthropic.com/en/docs/build-with-claude/structured-outputs)\n",
    "- [AG2 Documentation](https://docs.ag2.ai/)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/)"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Anthropic's structured outputs feature provides two powerful modes: JSON Outputs (Get validated JSON responses matching a specific schema) and Strict Tool Use (Guaranteed schema validation for tool inputs).",
   "tags": [
    "structured output",
    "anthropic"
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
