{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# AG2 + Gemini Thinking Config Variants\n",
    "\n",
    "Author: [Priyanshu Deshmukh](https://github.com/priyansh4320)\n",
    "\n",
    "This notebook shows how to adjust Gemini thinking features in AG2:\n",
    "- `thinking_budget` (token budget for thinking)\n",
    "- `thinking_level` (\"High\" vs \"Low\")\n",
    "- `include_thoughts` (whether to return thought summaries)\n",
    "\n",
    "Reference: [Gemini Thinking Guide](https://ai.google.dev/gemini-api/docs/thinking)\n",
    "\n",
    "Install AG2 with Google Gemini support:\n",
    "\n",
    "```bash\n",
    "pip install ag2[gemini]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"GOOGLE_GEMINI_API_KEY is not set. Please set it in your environment or .env file.\")\n",
    "\n",
    "prompt = \"\"\"You are playing the 20 question game. You know that what you are looking for\n",
    "    is an aquatic mammal that doesn't live in the sea, is venomous and that's\n",
    "    smaller than a cat. What could that be and how could you make sure?\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## AG2 now supports Google Gemini's `ThinkingConfig`\n",
    "ThinkConfig has three configuration, which are configured through LLMConfig item parameters:\n",
    "- `thinking budget`: Indicates the thinking budget in tokens. 0 is DISABLED. -1 is AUTOMATIC. The default values and allowed ranges are model dependent.\n",
    "- `thinking level`: The level of thoughts tokens that the model should generate.\n",
    "- `include_thoughts`: Indicates whether to include thoughts in the response. If true, thoughts are returned only if the model supports thought and thoughts are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example configuration for ThinkingConfig Support\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-3-pro-preview\",\n",
    "        \"api_type\": \"google\",\n",
    "        \"api_key\": api_key,\n",
    "        # \"thinking_budget\": 1000, # Thinking Budget or Thinking Level\n",
    "        \"thinking_level\": \"High\",  # Use the thinkingLevel parameter with Gemini 3 Pro. While thinkingBudget is accepted for backwards compatibility, using it with Gemini 3 Pro is recommended\n",
    "        \"include_thoughts\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2, user_input=True)\n",
    "\n",
    "response.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## thinking_budget\n",
    "The `thinking_budget` parameter, introduced with the Gemini 2.5 series, guides the model on the specific number of thinking tokens to use for reasoning.\n",
    "\n",
    ">Note: Use the `thinking_level` parameter with Gemini 3 Pro. While `thinking_budget` is accepted for backwards compatibility, using it with Gemini 3 Pro may result in suboptimal performance.\n",
    "\n",
    "0 is DISABLED. -1 is AUTOMATIC. The default values and allowed ranges are model dependent. the ranges can be found here: [thinking budget ranges](https://ai.google.dev/gemini-api/docs/thinking#:~:text=The%20following%20are%20thinkingBudget%20configuration%20details%20for%20each%20model%20type.%20You%20can%20disable%20thinking%20by%20setting%20thinkingBudget%20to%200.%20Setting%20the%20thinkingBudget%20to%20%2D1%20turns%20on%20dynamic%20thinking%2C%20meaning%20the%20model%20will%20adjust%20the%20budget%20based%20on%20the%20complexity%20of%20the%20request.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = 4096\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-2.5-flash\",\n",
    "        \"api_type\": \"google\",\n",
    "        \"api_key\": api_key,\n",
    "        \"thinking_budget\": budget,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2, user_input=True)\n",
    "\n",
    "response.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Vary `thinking_level`\n",
    "You can set `thinking_level` to \"low\" or \"high\" (which is the default for `gemini-3-pro-preview`) for `gemini-3-pro-preview` or `gemini-3-flash-preview`. `gemini-3-flash-preview` also supports \"medium\" or \"minimal\" (similar to no thinking). These settings will indicate to the model if it allowed to do a lot of thinking. Since the thinking process stays dynamic, `high` doesn't mean it will always use a lot of token in its thinking phase, just that it's allowed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"High\"\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-3-flash-preview\",\n",
    "        \"api_type\": \"google\",\n",
    "        \"api_key\": api_key,\n",
    "        \"thinking_level\": level,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2, user_input=True)\n",
    "\n",
    "response.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "`thinking_level` is **not** supported by Gemini 2.5 Flash (this code will throw an error). It is, however, supported by Gemini 3 Flash preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = \"Low\"\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-2.5-flash\",  # Note: \"gemini-3-flash-preview\" does support thinking_level\n",
    "        \"api_type\": \"google\",\n",
    "        \"api_key\": api_key,\n",
    "        \"thinking_level\": level,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent-thoughts\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2, user_input=True)\n",
    "\n",
    "# This will cause an exception as gemini-2.5-flash does not support thinking_level\n",
    "response.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## `include_thoughts`\n",
    "True/False to see thought summaries or no thoughts, respectively. Summaries of the model's thinking reveal its internal problem-solving pathway. Users can leverage this feature to check the model's strategy and remain informed during complex tasks.\n",
    "\n",
    "The agent's reply message will contain the thoughts first and then the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"model\": \"gemini-3-flash-preview\",\n",
    "        \"api_type\": \"google\",\n",
    "        \"api_key\": api_key,\n",
    "        \"thinking_budget\": 4096,\n",
    "        \"include_thoughts\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "agent = ConversableAgent(name=\"agent-thoughts\", description=\"you are a helpful assistant\", llm_config=llm_config)\n",
    "response = agent.run(message=prompt, max_turns=2, user_input=True)\n",
    "\n",
    "response.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Tips\n",
    "- For long/complex tasks, use a higher `thinking_budget`.\n",
    "- `thinking_level` can be lowered for lighter reasoning.\n",
    "- Set `include_thoughts=True` when you want thought summaries; turn off to reduce output.\n",
    "\n",
    "Reference: [Gemini Thinking Guide](https://ai.google.dev/gemini-api/docs/thinking)\n"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Google Gemini Thinking",
   "tags": [
    "google",
    "gemini",
    "thinking"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
