{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterating Over Agent Runs with AG2\n",
    "\n",
    "AG2's `run()` and `run_group_chat()` methods execute agent conversations in **background threads** that run independently of event consumption. This is great for streaming UIs, but makes it difficult to:\n",
    "\n",
    "- **Debug step-by-step** - Execution races ahead while you're inspecting events\n",
    "- **Implement human-in-the-loop** - Hard to pause for approval before each action  \n",
    "- **Build interactive tools** - Can't easily gate execution on user decisions\n",
    "\n",
    "**Run iteration** solves this by synchronizing the producer (background thread) and consumer (your code) - the producer blocks after each event until you advance to the next iteration.\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install AG2:\n",
    "\n",
    "```bash\n",
    "pip install ag2[openai]\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/installing-ag2).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up our LLM configuration and create some agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "load_dotenv(\"../.env.local\")\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create two agents for a simple conversation\n",
    "jack = ConversableAgent(\n",
    "    \"Jack\",\n",
    "    system_message=\"Your name is Jack and you are a comedian. Tell one short joke and then say FINISH.\",\n",
    "    is_termination_msg=lambda x: \"FINISH\" in x.get(\"content\", \"\"),\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "emma = ConversableAgent(\n",
    "    \"Emma\",\n",
    "    system_message=\"Your name is Emma. Laugh at Jack's joke and say FINISH.\",\n",
    "    llm_config=llm_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Run Iteration\n",
    "\n",
    "Use `run_iter()` instead of `run()` to iterate over events. This yields **every event** and uses Python's iteration protocol.\n",
    "\n",
    "Cleanup is automatic - the generator's `finally` block ensures the background thread exits cleanly even if an exception occurs or you break out of the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent\n",
    "\n",
    "# Iterate over every event\n",
    "event_count = 0\n",
    "result = jack.run_iter(emma, message=\"Emma, tell me a joke!\", max_turns=2)\n",
    "\n",
    "for event in result:\n",
    "    event_count += 1\n",
    "    print(f\"\\n[Event {event_count}] Event type: {event.type}\")\n",
    "\n",
    "    # Handle input requests - prompt user for input\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        user_input = input(\"  Input requested: \")\n",
    "        event.content.respond(user_input)\n",
    "        continue\n",
    "\n",
    "    # Access event content\n",
    "    if hasattr(event, \"content\") and hasattr(event.content, \"content\"):\n",
    "        content = str(event.content.content)\n",
    "        preview = content[:100] + \"...\" if len(content) > 100 else content\n",
    "        print(f\"  Content: {preview}\")\n",
    "\n",
    "print(f\"\\n[Event {event_count}] Run completed!\")\n",
    "print(f\"Total events: {event_count}\")\n",
    "print(f\"Summary: {result.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Events with `yield_on`\n",
    "\n",
    "In many cases, you don't need to yield every event. Use `yield_on` to specify which event types to yield.\n",
    "\n",
    "Common event types:\n",
    "- `TextEvent` - Agent sends/receives a text message\n",
    "- `ToolCallEvent` - Agent wants to call a tool\n",
    "- `ToolResponseEvent` - Tool returns a result\n",
    "- `TerminationEvent` - Conversation terminates\n",
    "\n",
    "**Special events** are always yielded regardless of filter:\n",
    "- `InputRequestEvent` - User must respond to input requests\n",
    "- `ErrorEvent` - Errors are raised as exceptions\n",
    "- `RunCompletionEvent` - Signals completion (iteration ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent, TerminationEvent, TextEvent\n",
    "\n",
    "# Only yield TextEvent and TerminationEvent\n",
    "# Note: InputRequestEvent is always yielded regardless of filter\n",
    "event_count = 0\n",
    "result = jack.run_iter(\n",
    "    emma,\n",
    "    message=\"Emma, tell me another joke!\",\n",
    "    max_turns=2,\n",
    "    yield_on=[TextEvent, TerminationEvent],\n",
    ")\n",
    "\n",
    "for event in result:\n",
    "    event_count += 1\n",
    "    print(f\"\\n[Event {event_count}] Event type: {event.type}\")\n",
    "\n",
    "    # Handle input requests - always yielded regardless of filter\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        user_input = input(\"  Input requested: \")\n",
    "        event.content.respond(user_input)\n",
    "        continue\n",
    "\n",
    "    if hasattr(event, \"content\"):\n",
    "        if hasattr(event.content, \"sender\"):\n",
    "            print(f\"  Sender: {event.content.sender}\")\n",
    "        if hasattr(event.content, \"content\"):\n",
    "            content = str(event.content.content)\n",
    "            preview = content[:100] + \"...\" if len(content) > 100 else content\n",
    "            print(f\"  Content: {preview}\")\n",
    "\n",
    "print(f\"\\n[Event {event_count}] Run completed!\")\n",
    "print(f\"Total events (with filter): {event_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating Group Chats\n",
    "\n",
    "Run iteration also works with `run_group_chat_iter()`. This is useful for monitoring multi-agent conversations.\n",
    "\n",
    "Use `GroupChatRunChatEvent` to yield when each agent takes their turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "from autogen.agentchat.group.multi_agent_chat import run_group_chat_iter\n",
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "from autogen.events.agent_events import GroupChatRunChatEvent, InputRequestEvent, TerminationEvent, TextEvent\n",
    "\n",
    "# Create agents for group chat\n",
    "coder = ConversableAgent(\n",
    "    \"Coder\",\n",
    "    system_message=\"You are a coder. Write a simple hello world function. Then say APPROVE to get approval.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "reviewer = ConversableAgent(\n",
    "    \"Reviewer\",\n",
    "    system_message=\"You are a code reviewer. If you see code, approve it by saying TERMINATE.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "user = ConversableAgent(\n",
    "    \"User\",\n",
    "    system_message=\"You are a user who wants code written.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "# Create pattern for group chat\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=coder,\n",
    "    agents=[coder, reviewer, user],\n",
    "    group_manager_args={\"llm_config\": llm_config},\n",
    ")\n",
    "\n",
    "# Run with step mode, yielding on agent turns\n",
    "for event in run_group_chat_iter(\n",
    "    pattern=pattern,\n",
    "    messages=\"Write a hello world function\",\n",
    "    max_rounds=4,\n",
    "    yield_on=[GroupChatRunChatEvent, TextEvent, TerminationEvent],\n",
    "):\n",
    "    # Handle input requests\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        user_input = input(\"  Input requested: \")\n",
    "        event.content.respond(user_input)\n",
    "        continue\n",
    "\n",
    "    if isinstance(event, GroupChatRunChatEvent):\n",
    "        print(f\"\\n=== {event.content.speaker}'s turn ===\")\n",
    "    elif isinstance(event, TextEvent):\n",
    "        content = str(event.content.content)[:200]\n",
    "        print(f\"  {content}\")\n",
    "\n",
    "print(\"\\n--- Run completed! ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aborting Execution Based on Events\n",
    "\n",
    "A key use case for run iteration is **inspecting events and aborting execution** if something unexpected happens. Since you control when to advance to the next event, you can break out of the loop at any time to stop the agent.\n",
    "\n",
    "This example shows how to:\n",
    "1. Monitor tool calls before they execute\n",
    "2. Abort if a tool call targets a blocked recipient\n",
    "3. Let the generator cleanup handle the background thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent, ToolCallEvent\n",
    "from autogen.tools import tool\n",
    "\n",
    "\n",
    "@tool(description=\"Send an email to a recipient\")\n",
    "def send_email(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an email (mock implementation).\"\"\"\n",
    "    print(f\"  [EXECUTING] Sending email to {recipient}...\")\n",
    "    return f\"Email sent to {recipient} with subject: {subject}\"\n",
    "\n",
    "\n",
    "# Create an agent with the email tool\n",
    "assistant = ConversableAgent(\n",
    "    \"Assistant\",\n",
    "    system_message=\"You are a helpful assistant. Use tools when asked. Say DONE when finished.\",\n",
    "    is_termination_msg=lambda x: \"DONE\" in x.get(\"content\", \"\"),\n",
    "    llm_config=llm_config,\n",
    "    functions=[send_email],\n",
    ")\n",
    "\n",
    "# List of blocked recipients\n",
    "BLOCKED_RECIPIENTS = [\"ceo@company.com\", \"legal@company.com\", \"hr@company.com\"]\n",
    "\n",
    "# Run with step mode - abort if agent tries to email a blocked recipient\n",
    "aborted = False\n",
    "for event in assistant.run_iter(\n",
    "    message=\"Send an email to ceo@company.com about the budget\",\n",
    "    max_turns=3,\n",
    "    yield_on=[TextEvent, ToolCallEvent, TerminationEvent],\n",
    "):\n",
    "    # Handle input requests\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        user_input = input(\"  Input requested: \")\n",
    "        event.content.respond(user_input)\n",
    "        continue\n",
    "\n",
    "    if isinstance(event, ToolCallEvent):\n",
    "        # Inspect the tool call arguments\n",
    "        for tool_call in event.content.tool_calls:\n",
    "            print(f\"\\n[TOOL CALL] {tool_call.function.name}\")\n",
    "            print(f\"  Arguments: {tool_call.function.arguments}\")\n",
    "\n",
    "            # Check if recipient is blocked\n",
    "            import json\n",
    "\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            recipient = args.get(\"recipient\", \"\")\n",
    "\n",
    "            if recipient in BLOCKED_RECIPIENTS:\n",
    "                print(f\"\\n[BLOCKED] Cannot send to {recipient} - aborting execution!\")\n",
    "                aborted = True\n",
    "                break  # Break inner loop\n",
    "\n",
    "        if aborted:\n",
    "            break  # Break outer loop - execution stops here\n",
    "\n",
    "    elif isinstance(event, TextEvent):\n",
    "        content = str(event.content.content)[:100]\n",
    "        print(f\"\\n[TEXT] {content}\")\n",
    "\n",
    "if aborted:\n",
    "    print(\"\\nExecution was aborted before the tool could run.\")\n",
    "    print(\"The email was NOT sent.\")\n",
    "else:\n",
    "    print(\"\\nRun completed normally.\")\n",
    "    print(\"Execution completed without issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Types Reference\n",
    "\n",
    "| Event Type | When It Fires | Always Yielded? |\n",
    "|------------|---------------|------------------|\n",
    "| `TextEvent` | Agent sends/receives a text message | No |\n",
    "| `ToolCallEvent` | Agent wants to call a tool | No |\n",
    "| `ToolResponseEvent` | Tool returns a result | No |\n",
    "| `ExecutedFunctionEvent` | Function execution completed | No |\n",
    "| `GroupChatRunChatEvent` | Agent selected to speak in group chat | No |\n",
    "| `TerminationEvent` | Conversation terminates | No |\n",
    "| `InputRequestEvent` | Human input requested | **Yes** |\n",
    "| `ErrorEvent` | Error occurred | **Yes** (raises exception) |\n",
    "| `RunCompletionEvent` | Run completed (always fires last) | **Yes** (iteration ends) |\n",
    "\n",
    "**Note**: Events marked \"Always Yielded\" bypass the `yield_on` filter because they require user action.\n",
    "\n",
    "See `autogen/events/agent_events.py` for the full list of events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Run iteration provides fine-grained control over agent execution:\n",
    "\n",
    "- **`run_iter()` / `a_run_iter()`** - Iterate over single-agent runs\n",
    "- **`run_group_chat_iter()` / `a_run_group_chat_iter()`** - Iterate over group chats\n",
    "- **`yield_on=[...]`** - Filter which events to yield\n",
    "- **`for event in ...`** - Simple Python iteration\n",
    "- **Automatic cleanup** - Generator handles cleanup on break or exception\n",
    "\n",
    "This is ideal for:\n",
    "\n",
    "- Debugging agent conversations\n",
    "- Monitoring and logging all events\n",
    "- Aborting execution based on conditions (e.g., blocked recipients, cost limits)\n",
    "- Building interactive agent applications"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Step-by-step execution for debugging and human-in-the-loop workflows",
   "tags": [
    "step-mode",
    "debugging",
    "human-in-the-loop",
    "run",
    "events",
    "run_iter",
    "run_group_chat_iter"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
