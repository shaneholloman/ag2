{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Outputs with Amazon Bedrock in AG2\n",
    "\n",
    "\n",
    "This notebook demonstrates how to use **structured outputs** with Amazon Bedrock in AG2. Structured outputs allow you to define a specific JSON schema that the model must follow, ensuring consistent and parseable responses.\n",
    "\n",
    "## What are Structured Outputs?\n",
    "\n",
    "Structured outputs enable you to:\n",
    "- **Define a schema**: Specify exactly what format you want the model's response in\n",
    "- **Get consistent results**: The model will always return data matching your schema\n",
    "- **Parse easily**: Responses are guaranteed to be valid JSON matching your structure\n",
    "- **Validate automatically**: Use Pydantic models to validate and type-check responses\n",
    "\n",
    "## How Bedrock Implements Structured Outputs\n",
    "\n",
    "Bedrock uses **Tool Use** (Function Calling) to implement structured outputs. When you provide a `response_format`, AG2:\n",
    "\n",
    "1. Creates a special tool with your schema as the input schema\n",
    "2. Forces the model to call this tool using `toolChoice`\n",
    "3. Extracts the structured data from the tool call\n",
    "4. Validates it against your Pydantic model or dict schema\n",
    "\n",
    "This approach is based on the [AWS Bedrock Converse API](https://aws.amazon.com/blogs/machine-learning/structured-data-response-with-amazon-bedrock-prompt-engineering-and-tool-use/).\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Python >= 3.10\n",
    "- AG2 installed: `pip install ag2`\n",
    "- `boto3` package: `pip install boto3`\n",
    "- AWS credentials configured (via environment variables, IAM role, or AWS credentials file)\n",
    "- A Bedrock model that supports Tool Use (e.g., Claude models)\n",
    "\n",
    "## Model Compatibility\n",
    "\n",
    "Not all Bedrock models support Tool Use. Models that **do support** structured outputs include:\n",
    "- `anthropic.claude-3-5-sonnet-20241022-v2:0`\n",
    "- `anthropic.claude-3-sonnet-20240229-v1:0`\n",
    "- `anthropic.claude-3-opus-20240229-v1:0`\n",
    "- `anthropic.claude-3-haiku-20240307-v1:0`\n",
    "\n",
    "Check the [Bedrock model documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html) for the latest list of models supporting Tool Use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install required packages if not already installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ag2 boto3 pydantic --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries and Configure AWS Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from autogen import ConversableAgent, LLMConfig\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Define Structured Output Models with Pydantic\n",
    "\n",
    "Pydantic models provide type safety and automatic validation. Let's create a model for math problem solving:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define structured output model for math problem solving\n",
    "class Step(BaseModel):\n",
    "    \"\"\"Represents a single step in solving a math problem.\"\"\"\n",
    "\n",
    "    explanation: str  # What operation or reasoning is being performed\n",
    "    output: str  # The result of this step\n",
    "\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    \"\"\"Complete structured response for a math problem solution.\"\"\"\n",
    "\n",
    "    steps: list[Step]  # List of all steps taken\n",
    "    final_answer: str  # The final answer\n",
    "\n",
    "    def format(self) -> str:\n",
    "        \"\"\"Format the structured output for human-readable display.\"\"\"\n",
    "        steps_output = \"\\n\".join(\n",
    "            f\"Step {i + 1}: {step.explanation}\\n  Output: {step.output}\" for i, step in enumerate(self.steps)\n",
    "        )\n",
    "        return f\"{steps_output}\\n\\nFinal Answer: {self.final_answer}\"\n",
    "\n",
    "\n",
    "print(\"Pydantic models defined:\")\n",
    "print(f\"- Step: {Step.model_json_schema()}\")\n",
    "print(f\"- MathReasoning: {MathReasoning.model_json_schema()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Configure Bedrock with Structured Outputs\n",
    "\n",
    "Now let's set up the LLM configuration with Bedrock and enable structured outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LLM with Bedrock and structured outputs\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"bedrock\",\n",
    "        \"model\": \"qwen.qwen3-coder-480b-a35b-v1:0\",\n",
    "        \"api_key\": os.getenv(\"BEDROCK_API_KEY\"),\n",
    "        \"aws_region\": os.getenv(\"AWS_REGION\", \"eu-north-1\"),\n",
    "        \"aws_access_key\": os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "        \"aws_secret_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"response_format\": MathReasoning,\n",
    "        \"aws_profile_name\": os.getenv(\"AWS_PROFILE\"),\n",
    "    },\n",
    "    cache_seed=42,  # Optional: for reproducible results\n",
    ")\n",
    "print(\"Bedrock LLM configuration created with structured outputs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Configuration Parameters\n",
    "\n",
    "- **`api_type: \"bedrock\"`**: Tells AG2 to use the Bedrock client\n",
    "- **`model`**: The Bedrock model ID (must support Tool Use)\n",
    "- **`aws_region`**: AWS region where Bedrock is available\n",
    "- **`response_format`**: Your Pydantic model or dict schema - this enables structured outputs\n",
    "\n",
    "**Note**: When `response_format` is provided, AG2 automatically:\n",
    "1. Converts your schema into a Bedrock tool definition\n",
    "2. Forces the model to use this tool via `toolChoice`\n",
    "3. Extracts and validates the structured response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create an Agent with Structured Outputs\n",
    "\n",
    "Create a `ConversableAgent` that will return structured responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with structured output capability\n",
    "math_agent = ConversableAgent(\n",
    "    name=\"math_assistant\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a helpful math assistant that solves problems step by step.\n",
    "    Always show your reasoning process clearly with explanations for each step.\n",
    "    Return your response in the structured format requested.\"\"\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "print(f\"Agent '{math_agent.name}' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Example 1 - Simple Equation with Structured Output\n",
    "\n",
    "Let's solve a simple equation and see the structured response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 1: Solve equation with structured output ===\")\n",
    "\n",
    "# Initiate chat with the agent\n",
    "result1 = math_agent.run(\n",
    "    message=\"Solve the equation: 2x + 5 = -25.\",\n",
    "    max_turns=5,\n",
    ").process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's parse and validate the structured response:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Example 2 - Complex Math Problem\n",
    "\n",
    "Let's try a more complex problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 2: Complex math problem ===\")\n",
    "\n",
    "result2 = math_agent.run(\n",
    "    message=\"Designed to cause debate; some solve \\\\((2+2)\\\\) first (4), then \\\\(8\\\\div 2\\\\) (4), then \\\\(4\\times 4\\\\) (16); others do \\\\(2\\times 4\\\\) (8) first, then \\\\(8\\\\div 8\\\\) (1). use 10 steps to solve\",\n",
    "    max_turns=5,\n",
    ").process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Using Dict Schema Instead of Pydantic Model\n",
    "\n",
    "You can also use a plain dictionary schema instead of a Pydantic model. This is useful when:\n",
    "- You don't need Pydantic's validation features\n",
    "- You want more flexibility in schema definition\n",
    "- You're working with dynamic schemas\n",
    "\n",
    "Let's create a different schema for a different use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema as a dictionary (JSON Schema format)\n",
    "dict_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"problem\": {\"type\": \"string\", \"description\": \"The math problem being solved\"},\n",
    "        \"solution_steps\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"step\": {\"type\": \"string\"}, \"result\": {\"type\": \"string\"}},\n",
    "                \"required\": [\"step\", \"result\"],\n",
    "            },\n",
    "        },\n",
    "        \"answer\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"problem\", \"solution_steps\", \"answer\"],\n",
    "}\n",
    "\n",
    "print(\"Dict schema defined:\")\n",
    "print(json.dumps(dict_schema, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new LLM config with dict schema\n",
    "llm_config_dict = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"bedrock\",\n",
    "        \"model\": \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        \"api_key\": os.getenv(\"BEDROCK_API_KEY\"),\n",
    "        \"aws_region\": os.getenv(\"AWS_REGION\", \"us-east-1\"),\n",
    "        \"aws_access_key\": os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "        \"aws_secret_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"response_format\": dict_schema,  # Using dict schema instead of Pydantic model\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create agent with dict schema\n",
    "math_agent_dict = ConversableAgent(\n",
    "    name=\"math_assistant_dict\",\n",
    "    llm_config=llm_config_dict,\n",
    "    system_message=\"You are a helpful math assistant.\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "print(\"Agent created with dict schema!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Example 3: Using dict schema ===\")\n",
    "\n",
    "result3 = math_agent_dict.run(\n",
    "    message=\"Solve: x^2 - 5x + 6 = 0\",\n",
    "    max_turns=5,\n",
    ").process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Understanding How It Works Under the Hood\n",
    "\n",
    "When you use `response_format` with Bedrock, AG2:\n",
    "\n",
    "1. **Converts your schema to a tool**: Your Pydantic model or dict schema becomes a Bedrock tool definition\n",
    "2. **Forces tool usage**: Sets `toolChoice` to force the model to call the structured output tool\n",
    "3. **Extracts the data**: Gets the structured data from the tool call's input\n",
    "4. **Validates**: If using Pydantic, validates the data against your model\n",
    "5. **Formats**: Returns the JSON string (or formatted string if your model has a `format()` method)\n",
    "\n",
    "Let's inspect what the tool configuration looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the tool that gets created from your schema\n",
    "from autogen.oai.bedrock import BedrockClient\n",
    "\n",
    "# Create a temporary client to see the tool creation\n",
    "temp_client = BedrockClient(\n",
    "    aws_region=os.getenv(\"AWS_REGION\", \"us-east-1\"),\n",
    "    aws_access_key=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    response_format=MathReasoning,\n",
    ")\n",
    "\n",
    "# See how the schema is converted to a tool\n",
    "tool = temp_client._create_structured_output_tool(MathReasoning)\n",
    "\n",
    "print(\"Tool definition created from MathReasoning schema:\")\n",
    "print(json.dumps(tool, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "- The tool name is `\"__structured_output\"` (a reserved name)\n",
    "- The `inputSchema` contains your JSON schema\n",
    "- The description explains it's for structured output generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Best Practices\n",
    "\n",
    "### 1. Choose the Right Model\n",
    "- Use Claude models (they have excellent tool use support)\n",
    "- Check model compatibility before using structured outputs\n",
    "\n",
    "### 2. Schema Design\n",
    "- Keep schemas simple and focused\n",
    "- Use descriptive field names and descriptions\n",
    "- Make required fields explicit\n",
    "\n",
    "### 3. Error Handling\n",
    "- Always wrap parsing in try/except blocks\n",
    "- Provide fallback behavior when structured output fails\n",
    "- Log errors for debugging\n",
    "\n",
    "### 4. Pydantic vs Dict Schema\n",
    "- **Use Pydantic** when you need:\n",
    "  - Type validation\n",
    "  - Automatic serialization/deserialization\n",
    "  - IDE autocomplete\n",
    "  - Custom formatting methods\n",
    "- **Use Dict Schema** when you need:\n",
    "  - Dynamic schemas\n",
    "  - Simpler setup\n",
    "  - No external dependencies\n",
    "\n",
    "### 5. Performance Considerations\n",
    "- Structured outputs add a small overhead (tool call)\n",
    "- Consider caching for repeated queries\n",
    "- Use `cache_seed` for reproducible results during development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: Advanced Example - Custom Formatting\n",
    "\n",
    "You can add custom formatting methods to your Pydantic models for better display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetailedMathReasoning(BaseModel):\n",
    "    \"\"\"Enhanced math reasoning with custom formatting.\"\"\"\n",
    "\n",
    "    problem: str\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "    verification: str | None = None\n",
    "\n",
    "    def format(self) -> str:\n",
    "        \"\"\"Custom formatted output with problem statement.\"\"\"\n",
    "        output = f\"Problem: {self.problem}\\n\\n\"\n",
    "        output += \"Solution Steps:\\n\"\n",
    "        for i, step in enumerate(self.steps, 1):\n",
    "            output += f\"  {i}. {step.explanation}\\n\"\n",
    "            output += f\"     â†’ {step.output}\\n\"\n",
    "        output += f\"\\nFinal Answer: {self.final_answer}\"\n",
    "        if self.verification:\n",
    "            output += f\"\\n\\nVerification: {self.verification}\"\n",
    "        return output\n",
    "\n",
    "    def to_markdown(self) -> str:\n",
    "        \"\"\"Export as Markdown format.\"\"\"\n",
    "        md = f\"## Problem\\n\\n{self.problem}\\n\\n\"\n",
    "        md += \"## Solution\\n\\n\"\n",
    "        for i, step in enumerate(self.steps, 1):\n",
    "            md += f\"### Step {i}\\n\\n\"\n",
    "            md += f\"**Explanation**: {step.explanation}\\n\\n\"\n",
    "            md += f\"**Result**: `{step.output}`\\n\\n\"\n",
    "        md += f\"## Final Answer\\n\\n`{self.final_answer}`\"\n",
    "        return md\n",
    "\n",
    "\n",
    "# Create agent with enhanced model\n",
    "enhanced_llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"bedrock\",\n",
    "        \"model\": \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        \"aws_region\": os.getenv(\"AWS_REGION\", \"us-east-1\"),\n",
    "        \"aws_access_key\": os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "        \"aws_secret_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"response_format\": DetailedMathReasoning,\n",
    "    },\n",
    ")\n",
    "\n",
    "enhanced_agent = ConversableAgent(\n",
    "    name=\"enhanced_math_assistant\",\n",
    "    llm_config=enhanced_llm_config,\n",
    "    system_message=\"You are a detailed math assistant. Always verify your answers.\",\n",
    "    max_consecutive_auto_reply=1,\n",
    ")\n",
    "\n",
    "print(\"Enhanced agent created with custom formatting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the enhanced agent\n",
    "result = enhanced_agent.run(\n",
    "    recipient=enhanced_agent,\n",
    "    message=\"Solve: 4x - 8 = 12. Show your work and verify the answer.\",\n",
    "    max_turns=10,\n",
    ").process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.group.patterns import AutoPattern\n",
    "\n",
    "# Create a simple reviewer agent (without structured output) to work with the enhanced agent\n",
    "reviewer_llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"bedrock\",\n",
    "        \"model\": \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        \"aws_region\": os.getenv(\"AWS_REGION\", \"us-east-1\"),\n",
    "        \"aws_access_key\": os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "        \"aws_secret_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        # No response_format - this agent will use regular text responses\n",
    "    },\n",
    ")\n",
    "\n",
    "reviewer_agent = ConversableAgent(\n",
    "    name=\"math_reviewer\",\n",
    "    llm_config=reviewer_llm_config,\n",
    "    system_message=\"You are a math reviewer. Review the solutions provided by the math assistant and provide feedback. Keep your reviews brief and constructive.\",\n",
    "    max_consecutive_auto_reply=1,\n",
    ")\n",
    "\n",
    "# Create AutoPattern for groupchat\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=enhanced_agent,\n",
    "    agents=[enhanced_agent, reviewer_agent],\n",
    "    group_manager_args={\n",
    "        \"llm_config\": enhanced_llm_config,  # Use same config for group manager\n",
    "    },\n",
    ")\n",
    "\n",
    "print(\"AutoPattern created with structured output agent!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupchat example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from autogen import ConversableAgent, LLMConfig, UserProxyAgent\n",
    "from autogen.agentchat import initiate_group_chat\n",
    "from autogen.agentchat.group.patterns.auto import AutoPattern\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Define structured output models\n",
    "class TaskDetails(BaseModel):\n",
    "    \"\"\"Details about the task being processed.\"\"\"\n",
    "\n",
    "    task_type: str\n",
    "    description: str\n",
    "    priority: str | None = None\n",
    "    requirements: list[str] = []\n",
    "\n",
    "\n",
    "class RoutingDecision(BaseModel):\n",
    "    \"\"\"Structured routing decision from the orchestrator.\"\"\"\n",
    "\n",
    "    request_analysis: str\n",
    "    task_details: TaskDetails\n",
    "    selected_agent: str\n",
    "    routing_reason: str\n",
    "    expected_outcome: str\n",
    "    next_steps: list[str] = []\n",
    "\n",
    "\n",
    "class WorkflowStatus(BaseModel):\n",
    "    \"\"\"Status of the current workflow execution.\"\"\"\n",
    "\n",
    "    current_stage: str\n",
    "    completed_stages: list[str] = []\n",
    "    pending_stages: list[str] = []\n",
    "    issues: list[str] = []\n",
    "    progress_percentage: int | None = None\n",
    "\n",
    "\n",
    "class PipelineOrchestrationResponse(BaseModel):\n",
    "    \"\"\"Complete structured response from the pipeline orchestrator.\"\"\"\n",
    "\n",
    "    routing_decision: RoutingDecision\n",
    "    workflow_status: WorkflowStatus | None = None\n",
    "\n",
    "    def format(self) -> str:\n",
    "        \"\"\"Format the structured output for human-readable display.\"\"\"\n",
    "        output = \"ğŸ¯ Pipeline Orchestration Decision\\n\"\n",
    "        output += f\"{'=' * 60}\\n\\n\"\n",
    "        output += f\"Request Analysis:\\n{self.routing_decision.request_analysis}\\n\\n\"\n",
    "        output += f\"Task Type: {self.routing_decision.task_details.task_type}\\n\"\n",
    "        output += f\"Description: {self.routing_decision.task_details.description}\\n\\n\"\n",
    "        output += \"Routing Decision:\\n\"\n",
    "        output += f\"  â†’ Selected Agent: {self.routing_decision.selected_agent}\\n\"\n",
    "        output += f\"  â†’ Reason: {self.routing_decision.routing_reason}\\n\"\n",
    "        output += f\"  â†’ Expected Outcome: {self.routing_decision.expected_outcome}\\n\"\n",
    "        if self.routing_decision.next_steps:\n",
    "            output += \"\\nNext Steps:\\n\"\n",
    "            for i, step in enumerate(self.routing_decision.next_steps, 1):\n",
    "                output += f\"  {i}. {step}\\n\"\n",
    "        if self.workflow_status:\n",
    "            output += \"\\nWorkflow Status:\\n\"\n",
    "            output += f\"  Current Stage: {self.workflow_status.current_stage}\\n\"\n",
    "            if self.workflow_status.completed_stages:\n",
    "                output += f\"  Completed: {', '.join(self.workflow_status.completed_stages)}\\n\"\n",
    "            if self.workflow_status.pending_stages:\n",
    "                output += f\"  Pending: {', '.join(self.workflow_status.pending_stages)}\\n\"\n",
    "        return output\n",
    "\n",
    "\n",
    "# Regular LLM config for other agents\n",
    "llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"bedrock\",\n",
    "        \"model\": \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        \"api_key\": os.getenv(\"BEDROCK_API_KEY\"),\n",
    "        \"aws_region\": os.getenv(\"AWS_REGION\"),\n",
    "        \"aws_access_key\": os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "        \"aws_secret_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"aws_profile_name\": os.getenv(\"AWS_PROFILE\"),\n",
    "    },\n",
    "    cache_seed=42,\n",
    ")\n",
    "\n",
    "orchestrator_llm_config = LLMConfig(\n",
    "    config_list={\n",
    "        \"api_type\": \"bedrock\",\n",
    "        \"model\": \"eu.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        \"api_key\": os.getenv(\"BEDROCK_API_KEY\"),\n",
    "        \"aws_region\": os.getenv(\"AWS_REGION\"),\n",
    "        \"aws_access_key\": os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "        \"aws_secret_key\": os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "        \"aws_profile_name\": os.getenv(\"AWS_PROFILE\"),\n",
    "        \"response_format\": PipelineOrchestrationResponse,\n",
    "    },\n",
    "    cache_seed=42,\n",
    ")\n",
    "\n",
    "print(\"Bedrock LLM configuration created with structured outputs!\")\n",
    "\n",
    "\n",
    "orchestrator = ConversableAgent(\n",
    "    name=\"pipeline_orchestrator\",\n",
    "    system_message=\"\"\"ğŸ¯ You are the Pipeline Orchestrator. Your role is to:\n",
    "    â€¢ Analyze user requests and determine the workflow path\n",
    "    â€¢ Route tasks to appropriate specialized agents\n",
    "    â€¢ Monitor pipeline progress and coordinate handoffs\n",
    "    â€¢ Report final results to the user\n",
    "\n",
    "    You MUST provide structured routing decisions that include:\n",
    "    - Analysis of the user's request\n",
    "    - Task type and details\n",
    "    - Selected agent and reasoning\n",
    "    - Expected outcome and next steps\n",
    "\n",
    "    Workflow Decision Logic:\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ 1. New project request? â†’ Route to project_creator      â”‚\n",
    "    â”‚ 2. Code development? â†’ Route to code_developer          â”‚\n",
    "    â”‚ 3. Code analysis needed? â†’ Route to code_quality_analyzerâ”‚\n",
    "    â”‚ 4. Configuration updates? â†’ Route to config_manager     â”‚\n",
    "    â”‚ 5. Build/deploy request? â†’ Route to build_deploy_agent  â”‚\n",
    "    â”‚ 6. Validation needed? â†’ Route to deployment_validator   â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    Always provide clear routing decisions with reasoning.\"\"\",\n",
    "    llm_config=orchestrator_llm_config,  # Use config with structured output\n",
    ")\n",
    "\n",
    "project_creator = ConversableAgent(\n",
    "    name=\"project_creator\",\n",
    "    system_message=\"\"\"ğŸ—ï¸ You are the Project Creator. Your role is to:\n",
    "    Use the APPLY_PATCH tool to:\n",
    "    âœ“ Create project structure and directories\n",
    "    âœ“ Generate initial files (README.md, .gitignore, LICENSE)\n",
    "    âœ“ Set up configuration files (package.json, requirements.txt, pom.xml)\n",
    "    âœ“ Create initial source code templates\n",
    "    âœ“ Set up test directory structure\n",
    "    Project Creation Checklist:\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ â–¡ Project directory structure created?       â”‚\n",
    "    â”‚ â–¡ Configuration files initialized?           â”‚\n",
    "    â”‚ â–¡ Initial source code files created?         â”‚\n",
    "    â”‚ â–¡ Test directory structure set up?           â”‚\n",
    "    â”‚ â–¡ Documentation files added?                 â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    After project creation:\n",
    "    â†’ Route to code_developer for implementation\n",
    "    Create clean, well-structured project foundations.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "\n",
    "code_developer = ConversableAgent(\n",
    "    name=\"code_developer\",\n",
    "    system_message=\"\"\"ğŸ’» You are the Code Developer. Your role is to:\n",
    "    Use the APPLY_PATCH tool to:\n",
    "    âœ“ Write application code and implement features\n",
    "    âœ“ Create modules, classes, and functions\n",
    "    âœ“ Add business logic and algorithms\n",
    "    âœ“ Implement API endpoints and routes\n",
    "    âœ“ Write unit tests for new code\n",
    "    Development Guidelines:\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ 1. Follow best practices and coding standardsâ”‚\n",
    "    â”‚ 2. Write clean, maintainable code            â”‚\n",
    "    â”‚ 3. Include proper error handling             â”‚\n",
    "    â”‚ 4. Add comprehensive unit tests              â”‚\n",
    "    â”‚ 5. Document complex logic                    â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "    After development:\n",
    "    â†’ Route to code_quality_analyzer for testing and validation\n",
    "    Write production-ready code with tests!\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "\n",
    "code_analyzer = ConversableAgent(\n",
    "    name=\"code_quality_analyzer\",\n",
    "    system_message=\"\"\"ğŸ” You are the Code Quality Analyzer. Your role is to:\n",
    "    Use the SHELL tool to:\n",
    "    âœ“ Run test suites: pytest, unittest, npm test, mvn test\n",
    "    âœ“ Run linters: pylint, flake8, black --check, eslint, prettier\n",
    "    âœ“ Check git status: git status, git diff, git log\n",
    "    âœ“ Analyze code coverage: coverage report, pytest --cov\n",
    "    âœ“ Check build status: npm run build, mvn compile\n",
    "    Analysis Checklist:\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ â–¡ All tests passing?                         â”‚\n",
    "    â”‚ â–¡ No linting errors?                         â”‚\n",
    "    â”‚ â–¡ Code coverage acceptable?                  â”‚\n",
    "    â”‚ â–¡ No merge conflicts?                        â”‚\n",
    "    â”‚ â–¡ Build successful?                          â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    Routing Rules:\n",
    "    â€¢ Issues found â†’ Route to code_fixer\n",
    "    â€¢ All checks pass â†’ Route to config_manager for CI/CD setup\n",
    "    Provide detailed analysis reports with specific issues identified.\"\"\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "\n",
    "user = UserProxyAgent(\n",
    "    name=\"user\", human_input_mode=\"TERMINATE\", code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False}\n",
    ")\n",
    "\n",
    "\n",
    "pattern = AutoPattern(\n",
    "    initial_agent=orchestrator,\n",
    "    agents=[\n",
    "        orchestrator,\n",
    "        project_creator,\n",
    "        code_developer,\n",
    "        code_analyzer,\n",
    "    ],\n",
    "    user_agent=user,\n",
    "    group_manager_args={\"llm_config\": orchestrator_llm_config},\n",
    ")\n",
    "\n",
    "result, context, last_agent = initiate_group_chat(\n",
    "    pattern=pattern,\n",
    "    messages=\"I want to create a new project. for a coffee machine business\",\n",
    "    max_rounds=5,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've learned:\n",
    "\n",
    "1. âœ… How to define structured output schemas using Pydantic models\n",
    "2. âœ… How to configure Bedrock with `response_format` for structured outputs\n",
    "3. âœ… How to create agents that return structured, parseable responses\n",
    "4. âœ… How to parse and validate structured responses\n",
    "5. âœ… How to use dict schemas as an alternative to Pydantic\n",
    "6. âœ… How structured outputs work under the hood with Bedrock Tool Use\n",
    "7. âœ… Best practices for error handling and schema design\n",
    "8. âœ… Advanced techniques like custom formatting methods\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try creating your own structured output schemas for different use cases\n",
    "- Experiment with different Bedrock models that support Tool Use\n",
    "- Combine structured outputs with other AG2 features like multi-agent conversations\n",
    "- Explore using structured outputs for data extraction and analysis tasks\n",
    "\n",
    "## References\n",
    "\n",
    "- [AG2 Documentation](https://docs.ag2.ai)\n",
    "- [Bedrock Converse API](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html)\n",
    "- [AWS Blog: Structured Data with Bedrock](https://aws.amazon.com/blogs/machine-learning/structured-data-response-with-amazon-bedrock-prompt-engineering-and-tool-use/)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/)\n",
    "- [Bedrock Model IDs](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html)"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Use Amazon Bedrock with AG2 to build applications that return structured data.",
   "tags": [
    "integration",
    "code generation",
    "bedrock",
    "amazon",
    "structured output",
    "pydantic"
   ]
  },
  "kernelspec": {
   "display_name": "ag2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
