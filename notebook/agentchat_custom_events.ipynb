{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Custom Events for Run Iteration\n",
    "\n",
    "AG2's `run_iter()` lets you yield specific event types using `yield_on`. While AG2 provides many built-in events (`TextEvent`, `ToolCallEvent`, etc.), you can also create **custom events** for your specific use cases.\n",
    "\n",
    "Custom events are useful for:\n",
    "- **Workflow checkpoints** - Pause at specific stages for validation\n",
    "- **Progress tracking** - Report status from within tools\n",
    "- **Custom gating** - Implement domain-specific pause conditions\n",
    "\n",
    "````{=mdx}\n",
    ":::info Requirements\n",
    "Install AG2:\n",
    "\n",
    "```bash\n",
    "pip install ag2[openai]\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](https://docs.ag2.ai/latest/docs/user-guide/basic-concepts/installing-ag2).\n",
    ":::\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Custom Event\n",
    "\n",
    "Custom events require three things:\n",
    "\n",
    "1. **Inherit from `BaseEvent`** - The base class for all AG2 events\n",
    "2. **Use the `@wrap_event` decorator** - Wraps the event for serialization\n",
    "3. **Class name must end with `Event`** - Enforced by the decorator\n",
    "\n",
    "Let's create a custom event for tracking data pipeline stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "from typing import Any\n",
    "\n",
    "from autogen.events.base_event import BaseEvent, resolve_print_callable, wrap_event\n",
    "\n",
    "\n",
    "@wrap_event\n",
    "class PipelineStageEvent(BaseEvent):\n",
    "    \"\"\"Custom event emitted when a data pipeline stage completes.\"\"\"\n",
    "\n",
    "    stage_name: str\n",
    "    records_processed: int\n",
    "    validation_passed: bool\n",
    "\n",
    "    def print(self, f: Callable[..., Any] | None = None) -> None:\n",
    "        \"\"\"Optional: Define how the event prints to console.\"\"\"\n",
    "        f = resolve_print_callable(f)\n",
    "        status = \"PASSED\" if self.validation_passed else \"FAILED\"\n",
    "        f(f\"[Pipeline] {self.stage_name}: {self.records_processed} records - {status}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emitting Custom Events\n",
    "\n",
    "To emit a custom event from within a tool or custom code, use `IOStream.get_default().send()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.io.base import IOStream\n",
    "\n",
    "\n",
    "def emit_pipeline_event(stage: str, records: int, passed: bool) -> None:\n",
    "    \"\"\"Helper to emit a pipeline stage event.\"\"\"\n",
    "    IOStream.get_default().send(\n",
    "        PipelineStageEvent(\n",
    "            stage_name=stage,\n",
    "            records_processed=records,\n",
    "            validation_passed=passed,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Data Pipeline with Validation Gates\n",
    "\n",
    "Let's build a realistic example: an AI agent that processes data through multiple pipeline stages. We'll use custom events to yield at each stage for human validation.\n",
    "\n",
    "First, let's set up our LLM configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "load_dotenv(\"../.env.local\")\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a tool that simulates a data pipeline. The tool emits our custom `PipelineStageEvent` at each stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from autogen.tools import tool\n",
    "\n",
    "\n",
    "@tool(description=\"Process data through a multi-stage pipeline: extract -> transform -> validate -> load\")\n",
    "def run_data_pipeline(source_name: str, record_count: int) -> str:\n",
    "    \"\"\"Simulates a data pipeline with multiple stages.\"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Stage 1: Extract\n",
    "    extracted = record_count\n",
    "    emit_pipeline_event(\"extract\", extracted, True)\n",
    "    results.append(f\"Extracted {extracted} records from {source_name}\")\n",
    "\n",
    "    # Stage 2: Transform\n",
    "    transformed = int(extracted * 0.95)  # Some records filtered\n",
    "    emit_pipeline_event(\"transform\", transformed, True)\n",
    "    results.append(f\"Transformed {transformed} records (filtered invalid)\")\n",
    "\n",
    "    # Stage 3: Validate\n",
    "    validation_passed = random.random() > 0.3  # 70% chance of passing\n",
    "    emit_pipeline_event(\"validate\", transformed, validation_passed)\n",
    "    if not validation_passed:\n",
    "        results.append(\"VALIDATION FAILED - data quality issues detected\")\n",
    "        return \"\\n\".join(results)\n",
    "    results.append(f\"Validated {transformed} records - all checks passed\")\n",
    "\n",
    "    # Stage 4: Load\n",
    "    emit_pipeline_event(\"load\", transformed, True)\n",
    "    results.append(f\"Loaded {transformed} records to destination\")\n",
    "\n",
    "    return \"\\n\".join(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create an agent with this tool and run it with `run_iter()`, yielding on our custom event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.events.agent_events import InputRequestEvent, TerminationEvent, TextEvent, ToolCallEvent\n",
    "\n",
    "# Create the data engineer agent\n",
    "data_engineer = ConversableAgent(\n",
    "    \"DataEngineer\",\n",
    "    system_message=\"\"\"You are a data engineer. When asked to process data, use the run_data_pipeline tool.\n",
    "After processing, report the results. Say DONE when finished.\"\"\",\n",
    "    is_termination_msg=lambda x: \"DONE\" in x.get(\"content\", \"\"),\n",
    "    llm_config=llm_config,\n",
    "    functions=[run_data_pipeline],\n",
    ")\n",
    "\n",
    "# Run iteration, yielding on our custom PipelineStageEvent\n",
    "for event in data_engineer.run_iter(\n",
    "    message=\"Process 1000 records from the 'sales_data' source\",\n",
    "    max_turns=3,\n",
    "    yield_on=[PipelineStageEvent, TextEvent, ToolCallEvent, TerminationEvent],\n",
    "):\n",
    "    # Handle input requests\n",
    "    if isinstance(event, InputRequestEvent):\n",
    "        user_input = input(\"  Input requested: \")\n",
    "        event.content.respond(user_input)\n",
    "        continue\n",
    "\n",
    "    # Handle our custom pipeline event\n",
    "    if isinstance(event, PipelineStageEvent):\n",
    "        stage = event.content.stage_name\n",
    "        records = event.content.records_processed\n",
    "        passed = event.content.validation_passed\n",
    "        status = \"PASSED\" if passed else \"FAILED\"\n",
    "        print(f\"\\n[PIPELINE STAGE] {stage.upper()}\")\n",
    "        print(f\"  Records: {records}\")\n",
    "        print(f\"  Status: {status}\")\n",
    "\n",
    "        # You could add human approval here:\n",
    "        # if stage == \"validate\" and not passed:\n",
    "        #     approval = input(\"  Continue despite validation failure? (y/n): \")\n",
    "        #     if approval.lower() != 'y':\n",
    "        #         break  # Abort the pipeline\n",
    "        continue\n",
    "\n",
    "    # Handle other events\n",
    "    if isinstance(event, ToolCallEvent):\n",
    "        for tool_call in event.content.tool_calls:\n",
    "            print(f\"\\n[TOOL CALL] {tool_call.function.name}\")\n",
    "    elif isinstance(event, TextEvent):\n",
    "        content = str(event.content.content)[:150]\n",
    "        print(f\"\\n[TEXT] {content}\")\n",
    "\n",
    "print(\"\\n--- Pipeline run completed! ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the Event Wrapper Works\n",
    "\n",
    "The `@wrap_event` decorator transforms your event class:\n",
    "\n",
    "1. **Adds a `type` field** - Converted from class name (e.g., `PipelineStageEvent` â†’ `\"pipeline_stage\"`)\n",
    "2. **Wraps in a content structure** - Your fields are accessed via `event.content.<field>`\n",
    "3. **Enables serialization** - Events can be serialized for logging or transmission\n",
    "\n",
    "Example structure after wrapping:\n",
    "```python\n",
    "# Before wrapping (your class)\n",
    "class PipelineStageEvent(BaseEvent):\n",
    "    stage_name: str\n",
    "    records_processed: int\n",
    "    validation_passed: bool\n",
    "\n",
    "# After wrapping (what you receive)\n",
    "event.type           # \"pipeline_stage\"\n",
    "event.content.stage_name\n",
    "event.content.records_processed\n",
    "event.content.validation_passed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "To create custom events for run iteration:\n",
    "\n",
    "1. **Define the event class**:\n",
    "   - Inherit from `BaseEvent`\n",
    "   - Decorate with `@wrap_event`\n",
    "   - Name must end with `Event`\n",
    "   - Define fields using Pydantic-style type hints\n",
    "\n",
    "2. **Emit the event**:\n",
    "   - Use `IOStream.get_default().send(YourEvent(...))`\n",
    "   - Emit from tools, hooks, or custom agent code\n",
    "\n",
    "3. **Yield on the event**:\n",
    "   - Use `run_iter()` with `yield_on=[YourEvent, ...]`\n",
    "   - Check for it with `isinstance(event, YourEvent)`\n",
    "   - Access fields via `event.content.<field>`\n",
    "\n",
    "This pattern enables powerful workflows like:\n",
    "\n",
    "- Validation gates in data pipelines\n",
    "- Human approval at critical checkpoints\n",
    "- Progress monitoring for long-running tasks\n",
    "- Custom logging and analytics"
   ]
  }
 ],
 "metadata": {
  "front_matter": {
   "description": "Creating and using custom events for step-by-step execution",
   "tags": [
    "custom-events",
    "run-iter",
    "events",
    "extensibility"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
